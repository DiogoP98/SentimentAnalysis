{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "jdw4MOBVGsec",
    "outputId": "d849cae7-765a-47b5-cd72-0ae5633ee202"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJ6xy-PAEMAI"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "import numpy as np\n",
    "import time\n",
    "import en_core_web_sm\n",
    "import datetime\n",
    "from torch import nn\n",
    "import sys\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torchtext.vocab\n",
    "from torchtext import data\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_wHozmeEQUs"
   },
   "outputs": [],
   "source": [
    "from torchtext.data import Field, Dataset, Example\n",
    "import pandas as pd\n",
    "\n",
    "class DataFrameDataset(Dataset):\n",
    "    \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n",
    "\n",
    "    def __init__(self, examples, fields, filter_pred=None):\n",
    "        \"\"\"\n",
    "        Create a dataset from a pandas dataframe of examples and Fields\n",
    "        Arguments:\n",
    "            examples pd.DataFrame: DataFrame of examples\n",
    "            fields {str: Field}: The Fields to use in this tuple. The\n",
    "                string is a field name, and the Field is the associated field.\n",
    "            filter_pred (callable or None): use only exanples for which\n",
    "                filter_pred(example) is true, or use all examples if None.\n",
    "                Default is None\n",
    "        \"\"\"\n",
    "        self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n",
    "        if filter_pred is not None:\n",
    "            self.examples = filter(filter_pred, self.examples)\n",
    "        self.fields = dict(fields)\n",
    "        # Unpack field tuples\n",
    "        for n, f in list(self.fields.items()):\n",
    "            if isinstance(n, tuple):\n",
    "                self.fields.update(zip(n, f))\n",
    "                del self.fields[n]\n",
    "\n",
    "\n",
    "class SeriesExample(Example):\n",
    "    \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def fromSeries(cls, data, fields):\n",
    "        return cls.fromdict(data.to_dict(), fields)\n",
    "\n",
    "    @classmethod\n",
    "    def fromdict(cls, data, fields):\n",
    "        ex = cls()\n",
    "\n",
    "        for key, field in fields.items():\n",
    "            if key not in data:\n",
    "                raise ValueError(\"Specified key {} was not found in \"\n",
    "                                 \"the input data\".format(key))\n",
    "            if field is not None:\n",
    "                setattr(ex, key, field.preprocess(data[key]))\n",
    "            else:\n",
    "                setattr(ex, key, data[key])\n",
    "\n",
    "\n",
    "        return ex\n",
    "\n",
    "def three_class_problem(df):\n",
    "  \n",
    "  df = df[df['overall'] != 2]\n",
    "  df = df[df['overall'] != 4]\n",
    "  df.loc[df['overall'] == 1, 'overall'] = 0\n",
    "  df.loc[df['overall'] == 3, 'overall'] = 1\n",
    "  df.loc[df['overall'] == 5, 'overall'] = 2\n",
    "\n",
    "  return df\n",
    "\n",
    "\n",
    "# def create_iterator(train_data, valid_data, test_data, batch_size, device):\n",
    "#     #  BucketIterator : Defines an iterator that batches examples of similar lengths together to minimize the amount of padding needed.\n",
    "#     # by setting sort_within_batch = True.\n",
    "#     train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((train_data, valid_data, test_data),\n",
    "#         batch_size = batch_size,\n",
    "#         sort_key = lambda x: len(x.reviewText), # Sort the batches by text length size\n",
    "#         sort_within_batch = True,\n",
    "#         device = device)\n",
    "#     return train_iterator, valid_iterator, test_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZeRkK9duETQM",
    "outputId": "f04f1f93-6604-4026-90e8-f7afdf9cef58",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# root_path = \"/content/drive/My Drive/notebooks\"\n",
    "# # For Google colab only\n",
    "\n",
    "df = pd.read_csv(f\"../Datasets/new_clean_sm_100000.csv\")\n",
    "df = df[df['reviewText'].notna()]\n",
    "df = df[~df['reviewText'].str.contains(\".jpg|.png|.jpeg|.tiff|.gif|.bmp|.heif\", regex=True, na=False)]\n",
    "df = three_class_problem(df)\n",
    "#df[\"overall\"] = df[\"overall\"].apply(lambda x: x - 1)\n",
    "train_df, validate_df, test_df = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rtwXUWOETi8",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# credit to https://github.com/Shawn1993/cnn-text-classification-pytorch for the TextCNN model\n",
    "\n",
    "class CNN_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, embed_num, embed_dim, class_num, kernel_num,kernel_sizes):\n",
    "        super(CNN_Text, self).__init__()\n",
    "       \n",
    "        \n",
    "        V = embed_num\n",
    "        D = embed_dim\n",
    "        C = class_num\n",
    "        Ci = 1\n",
    "        Co = kernel_num\n",
    "        Ks = kernel_sizes\n",
    "\n",
    "        self.embed = nn.Embedding(V, D)\n",
    "        # self.convs1 = [nn.Conv2d(Ci, Co, (K, D)) for K in Ks]\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])\n",
    "        '''\n",
    "        self.conv13 = nn.Conv2d(Ci, Co, (3, D))\n",
    "        self.conv14 = nn.Conv2d(Ci, Co, (4, D))\n",
    "        self.conv15 = nn.Conv2d(Ci, Co, (5, D))\n",
    "        '''\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(len(Ks)*Co, C)\n",
    "\n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3)  # (N, Co, W)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)  # (N, W, D)\n",
    "        \n",
    "        #if self.args.static:\n",
    "         #   x = Variable(x)\n",
    "\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
    "\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
    "\n",
    "        x = torch.cat(x, 1)\n",
    "\n",
    "        '''\n",
    "        x1 = self.conv_and_pool(x,self.conv13) #(N,Co)\n",
    "        x2 = self.conv_and_pool(x,self.conv14) #(N,Co)\n",
    "        x3 = self.conv_and_pool(x,self.conv15) #(N,Co)\n",
    "        x = torch.cat((x1, x2, x3), 1) # (N,len(Ks)*Co)\n",
    "        '''\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        logit = self.fc1(x)  # (N, C)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRvWP_x0FgKE",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".vector_cache\\glove.6B.zip: 862MB [06:46, 2.12MB/s]                               \n",
      "100%|█████████▉| 399999/400000 [00:17<00:00, 22375.78it/s]\n"
     ]
    }
   ],
   "source": [
    "#df, num_classes = three_class_problem(df)\n",
    "max_document_length = 256  # each sentence has until 100 words\n",
    "max_size = 5000 # maximum vocabulary size\n",
    "en = en_core_web_sm.load()\n",
    "def tokenize_en(sentence):\n",
    "    return [tok.text for tok in en.tokenizer(sentence)]\n",
    "\n",
    "Text = data.Field(tokenize=tokenize_en, batch_first=True, include_lengths=True, fix_length=max_document_length) # fix_length - make the sentences padded in the same lengths for all the batches\n",
    "Label = data.Field(sequential=False, use_vocab=False, pad_token=None, unk_token=None)\n",
    "fields = { 'overall' : Label, 'reviewText' : Text }\n",
    "train_ds = DataFrameDataset(train_df, fields)\n",
    "test_ds = DataFrameDataset(test_df, fields)\n",
    "valid_ds = DataFrameDataset(validate_df, fields)\n",
    "\n",
    "Text.build_vocab(train_ds, max_size=max_size, vectors=\"glove.6B.100d\")\n",
    "Label.build_vocab(train_ds)\n",
    "vocab_size = len(Text.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ukaB0Cr3dXYk",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def train(train_iter, dev_iter, model):\n",
    " \n",
    "    device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(device)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "    steps = 0\n",
    "    best_acc = 0\n",
    "    last_step = 0\n",
    "    model.train()\n",
    "    for epoch in (range(1, 2+0)):\n",
    "        for batch in tqdm(train_iter, total=len(train_iter)):\n",
    "            #feature.data.t_(), target.data.sub_(1)  # batch first, index align\n",
    "\n",
    "            feature, _ =  batch.reviewText\n",
    "            target = batch.overall\n",
    "            feature, target = feature.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logit = model(feature)\n",
    "\n",
    "            #print('logit vector', logit.size())\n",
    "            #print('target vector', target.size())\n",
    "            loss = F.cross_entropy(logit, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            steps += 1\n",
    "            if steps % 100 == 0:\n",
    "                corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "                accuracy = 100.0 * corrects/batch.batch_size\n",
    "                print(\n",
    "                    '\\rBatch[{}] - loss: {:.6f}  acc: {:.4f}%({}/{})'.format(steps, \n",
    "                                                                             loss.item(), \n",
    "                                                                             accuracy,\n",
    "                                                                             corrects,\n",
    "                                                                             batch.batch_size))\n",
    "            if steps % 100 == 0:\n",
    "                dev_acc, valid_f1 = eval(dev_iter, model)\n",
    "                if dev_acc > best_acc:\n",
    "                    best_acc = dev_acc\n",
    "                    last_step = steps\n",
    "                    #if args.save_best:\n",
    "                     #   save(model, args.save_dir, 'best', steps)\n",
    "                else:\n",
    "                    if steps - last_step >= 1000:\n",
    "                        print('early stop by {} steps.'.format(1000))\n",
    "            \n",
    "\n",
    "\n",
    "def eval(data_iter, model):\n",
    "    model.eval()\n",
    "    corrects, avg_loss,  epoch_f1 = 0 , 0, 0\n",
    "    for batch in data_iter:\n",
    "      \n",
    "        #feature.data.t_(), target.data.sub_(1)  # batch first, index align\n",
    "\n",
    "        feature, _ =  batch.reviewText\n",
    "        target = batch.overall\n",
    "        feature, target = feature.to(device), target.to(device)\n",
    "\n",
    "\n",
    "        logit = model(feature)\n",
    "        loss = F.cross_entropy(logit, target, size_average=False)\n",
    "        f1 = f1_score(logit.argmax(dim=1).cpu().numpy(), batch.overall.cpu().numpy(), average='macro')\n",
    "\n",
    "\n",
    "        avg_loss += loss.item()\n",
    "        corrects += (torch.max(logit, 1)\n",
    "                     [1].view(target.size()).data == target.data).sum()\n",
    "        epoch_f1 += f1\n",
    "\n",
    "    size = len(data_iter.dataset)\n",
    "    avg_loss /= size\n",
    "    accuracy = 100.0 * corrects/size\n",
    "    print('\\nEvaluation - loss: {:.6f}  acc: {:.4f}%({}/{}) \\n'.format(avg_loss, \n",
    "                                                                       accuracy, \n",
    "                                                                       corrects, \n",
    "                                                                       size))\n",
    "    print(f'\\t F1 score is {epoch_f1/len(data_iter)}')\n",
    "    return accuracy, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "colab_type": "code",
    "id": "hb1x2CTFF5f8",
    "outputId": "439cafef-7219-48d6-db80-bde1d8500ab8",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 99/2809 [00:11<03:59, 11.30it/s] C:\\Users\\grthy\\Anaconda3\\envs\\deeplab\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Batch[100] - loss: 0.995513  acc: 50.0000%(32/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 102/2809 [01:22<11:17:58, 15.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation - loss: 0.840985  acc: 62.0423%(37177/59922) \n",
      "\n",
      "\t F1 score is 0.6023702828953914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 198/2809 [01:30<03:22, 12.88it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Batch[200] - loss: 0.611691  acc: 67.1875%(43/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 202/2809 [02:42<5:30:09,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation - loss: 0.714516  acc: 69.2200%(41478/59922) \n",
      "\n",
      "\t F1 score is 0.6829304450265955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 298/2809 [02:49<03:16, 12.76it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Batch[300] - loss: 0.649660  acc: 71.8750%(46/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 300/2809 [03:57<7:09:54, 10.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation - loss: 0.664756  acc: 71.0958%(42602/59922) \n",
      "\n",
      "\t F1 score is 0.7026862505915326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 398/2809 [04:05<03:04, 13.07it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Batch[400] - loss: 0.641592  acc: 71.8750%(46/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 400/2809 [05:13<6:55:34, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation - loss: 0.702569  acc: 68.1102%(40813/59922) \n",
      "\n",
      "\t F1 score is 0.6688779790921933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 498/2809 [05:21<02:59, 12.84it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Batch[500] - loss: 0.498749  acc: 78.1250%(50/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 502/2809 [06:29<4:35:06,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation - loss: 0.606805  acc: 74.0513%(44373/59922) \n",
      "\n",
      "\t F1 score is 0.7328721962852444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 599/2809 [06:39<03:58,  9.25it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Batch[600] - loss: 0.643773  acc: 70.3125%(45/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 602/2809 [07:50<9:10:45, 14.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation - loss: 0.622776  acc: 73.2235%(43877/59922) \n",
      "\n",
      "\t F1 score is 0.7263802001829959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 698/2809 [07:58<02:42, 12.98it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Batch[700] - loss: 0.530082  acc: 73.4375%(47/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 702/2809 [09:12<4:35:35,  7.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation - loss: 0.579055  acc: 75.5349%(45262/59922) \n",
      "\n",
      "\t F1 score is 0.7462570119760988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 798/2809 [09:19<02:32, 13.16it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Batch[800] - loss: 0.709965  acc: 70.3125%(45/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 802/2809 [10:32<4:15:59,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation - loss: 0.575463  acc: 75.4014%(45182/59922) \n",
      "\n",
      "\t F1 score is 0.7438798729799527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 898/2809 [10:39<02:23, 13.36it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Batch[900] - loss: 0.724248  acc: 67.1875%(43/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 902/2809 [11:47<3:48:56,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation - loss: 0.613215  acc: 73.4438%(44009/59922) \n",
      "\n",
      "\t F1 score is 0.7194670813331122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 998/2809 [11:54<02:20, 12.85it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Batch[1000] - loss: 0.628925  acc: 70.3125%(45/64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 998/2809 [12:10<02:20, 12.85it/s]"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "embed_num = vocab_size\n",
    "embed_dim = 128\n",
    "class_num = 3\n",
    "kernel_num = 100\n",
    "kernel_sizes = [3,4,5]\n",
    "batch_size = 64\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class MyIter:\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "    def __iter__(self):\n",
    "        for batch in self.it:\n",
    "            yield (batch.reviewText, batch.overall.unsqueeze(1))\n",
    "    def __len__(self):\n",
    "        return len(self.it)\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_ds, valid_ds, test_ds), \n",
    "    batch_size=batch_size,\n",
    "    device=device,\n",
    "    sort_key=lambda x: len(x.reviewText),\n",
    "    sort_within_batch=True)\n",
    "\n",
    "\n",
    "cnn = CNN_Text(embed_num,embed_dim,class_num,kernel_num,kernel_sizes)\n",
    "train(train_iterator, valid_iterator, cnn)\n",
    "#train_iterator, valid_iterator, test_iterator = create_iterator(train_ds, valid_ds, test_ds, batch_size, device)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ED4Z5iTRGw_Q",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(f\"FINAL OUPUT IS \\n{eval(test_iterator,cnn)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xxbA9oS_HRVk",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "az2uey3AX01Y",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "TextCNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}