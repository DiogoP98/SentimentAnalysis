{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "MLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "jdw4MOBVGsec",
    "colab_type": "code",
    "outputId": "d849cae7-765a-47b5-cd72-0ae5633ee202",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    }
   },
   "source": [
    "!pip install torchbearer\n",
    "!pip install progress"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchbearer in /usr/local/lib/python3.6/dist-packages (0.5.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchbearer) (1.18.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchbearer) (4.41.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from torchbearer) (1.5.0+cu101)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0.0->torchbearer) (0.16.0)\n",
      "Requirement already satisfied: progress in /usr/local/lib/python3.6/dist-packages (1.5)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DJ6xy-PAEMAI",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, random_split, DataLoader\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "from torch import nn\n",
    "import sys\n",
    "import os\n",
    "from progress.bar import IncrementalBar\n",
    "from tqdm import tqdm\n",
    "import torchtext.vocab\n",
    "from torchtext import data\n",
    "import pandas as pd"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o_wHozmeEQUs",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from torchtext.data import Field, Dataset, Example\n",
    "import pandas as pd\n",
    "\n",
    "class DataFrameDataset(Dataset):\n",
    "    \"\"\"Class for using pandas DataFrames as a datasource\"\"\"\n",
    "\n",
    "    def __init__(self, examples, fields, filter_pred=None):\n",
    "        \"\"\"\n",
    "        Create a dataset from a pandas dataframe of examples and Fields\n",
    "        Arguments:\n",
    "            examples pd.DataFrame: DataFrame of examples\n",
    "            fields {str: Field}: The Fields to use in this tuple. The\n",
    "                string is a field name, and the Field is the associated field.\n",
    "            filter_pred (callable or None): use only exanples for which\n",
    "                filter_pred(example) is true, or use all examples if None.\n",
    "                Default is None\n",
    "        \"\"\"\n",
    "        self.examples = examples.apply(SeriesExample.fromSeries, args=(fields,), axis=1).tolist()\n",
    "        if filter_pred is not None:\n",
    "            self.examples = filter(filter_pred, self.examples)\n",
    "        self.fields = dict(fields)\n",
    "        # Unpack field tuples\n",
    "        for n, f in list(self.fields.items()):\n",
    "            if isinstance(n, tuple):\n",
    "                self.fields.update(zip(n, f))\n",
    "                del self.fields[n]\n",
    "\n",
    "\n",
    "class SeriesExample(Example):\n",
    "    \"\"\"Class to convert a pandas Series to an Example\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def fromSeries(cls, data, fields):\n",
    "        return cls.fromdict(data.to_dict(), fields)\n",
    "\n",
    "    @classmethod\n",
    "    def fromdict(cls, data, fields):\n",
    "        ex = cls()\n",
    "\n",
    "        for key, field in fields.items():\n",
    "            if key not in data:\n",
    "                raise ValueError(\"Specified key {} was not found in \"\n",
    "                                 \"the input data\".format(key))\n",
    "            if field is not None:\n",
    "                setattr(ex, key, field.preprocess(data[key]))\n",
    "            else:\n",
    "                setattr(ex, key, data[key])\n",
    "\n",
    "\n",
    "        return ex\n",
    "\n",
    "def three_class_problem(df):\n",
    "  \n",
    "  df = df[df['overall'] != 2]\n",
    "  df = df[df['overall'] != 4]\n",
    "  df.loc[df['overall'] == 1, 'overall'] = 0\n",
    "  df.loc[df['overall'] == 3, 'overall'] = 1\n",
    "  df.loc[df['overall'] == 5, 'overall'] = 2\n",
    "\n",
    "  return df\n",
    "\n",
    "\n",
    "\n",
    "# def create_iterator(train_data, valid_data, test_data, batch_size, device):\n",
    "#     #  BucketIterator : Defines an iterator that batches examples of similar lengths together to minimize the amount of padding needed.\n",
    "#     # by setting sort_within_batch = True.\n",
    "#     train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits((train_data, valid_data, test_data),\n",
    "#         batch_size = batch_size,\n",
    "#         sort_key = lambda x: len(x.reviewText), # Sort the batches by text length size\n",
    "#         sort_within_batch = True,\n",
    "#         device = device)\n",
    "#     return train_iterator, valid_iterator, test_iterator"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZeRkK9duETQM",
    "colab_type": "code",
    "outputId": "028ee5fe-70ce-4ee5-af50-b1cc0795d26e",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "root_path = \"/content/drive/My Drive/notebooks\"\n",
    "# For Google colab only\n",
    "\n",
    "df = pd.read_csv(f\"{root_path}/new_clean_sm_100000.csv\")\n",
    "df = df[df['reviewText'].notna()]\n",
    "df = df[~df['reviewText'].str.contains(\".jpg|.png|.jpeg|.tiff|.gif|.bmp|.heif\", regex=True, na=False)]\n",
    "df = three_class_problem(df)\n",
    "#df[\"overall\"] = df[\"overall\"].apply(lambda x: x - 1)\n",
    "train_df, validate_df, test_df = np.split(df.sample(frac=1), [int(.6*len(df)), int(.8*len(df))])\n",
    "\n",
    "\n"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9rtwXUWOETi8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size2, hidden_size3, hidden_size4, output_dim, dropout, max_document_length):\n",
    "        super().__init__()\n",
    "\n",
    "        # embedding and convolution layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(embed_size*max_document_length, hidden_size2)  # dense layer\n",
    "        self.fc2 = nn.Linear(hidden_size2, hidden_size3)  # dense layer\n",
    "        self.fc3 = nn.Linear(hidden_size3, hidden_size4)  # dense layer\n",
    "        self.fc4 = nn.Linear(hidden_size4, output_dim)  # dense layer\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text shape = (batch_size, num_sequences)\n",
    "        embedded = self.embedding(text)\n",
    "        # embedded = [batch size, sent_len, emb dim]\n",
    "\n",
    "        x = embedded.view(embedded.shape[0], -1)  # x = Flatten()(x)\n",
    "        #embedded = embedded.unsqueeze(1) # fc gets 4 dimension\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.dropout(x)\n",
    "        preds = self.fc4(x)\n",
    "        #preds = F.softmax(preds, 1)\n",
    "        #labels = torch.max(preds, 1)\n",
    "        #print(f\"preds is {preds}\")\n",
    "        return preds"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yRvWP_x0FgKE",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "#df, num_classes = three_class_problem(df)\n",
    "max_document_length = 100  # each sentence has until 100 words\n",
    "max_size = 5000 # maximum vocabulary size\n",
    "\n",
    "Text = data.Field(tokenize='spacy', batch_first=True, include_lengths=True, fix_length=max_document_length) # fix_length - make the sentences padded in the same lengths for all the batches\n",
    "Label = data.Field(sequential=False, use_vocab=False, pad_token=None, unk_token=None)\n",
    "fields = { 'overall' : Label, 'reviewText' : Text }\n",
    "train_ds = DataFrameDataset(train_df, fields)\n",
    "test_ds = DataFrameDataset(test_df, fields)\n",
    "valid_ds = DataFrameDataset(validate_df, fields)\n",
    "\n",
    "Text.build_vocab(train_ds, max_size=max_size)\n",
    "Label.build_vocab(train_ds)\n",
    "vocab_size = len(Text.vocab)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hb1x2CTFF5f8",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "outputId": "a3aeb92d-90b2-42d9-ccd9-9c547718be81"
   },
   "source": [
    "def run_train(epochs, model, train_iterator, valid_iterator, optimizer, criterion, model_type, device):\n",
    "    best_valid_loss = float('inf')\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # train the model\n",
    "        train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "\n",
    "        # evaluate the model\n",
    "        valid_loss, valid_acc, valid_f1 = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "\n",
    "        # save the best model\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            #torch.save(model.state_dict(), 'saved_weights'+'_'+model_type+'.pt')\n",
    "\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.2f}%')\n",
    "        print(f'\\t F1 score is {valid_f1}')\n",
    "\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    for batch in tqdm(iterator):\n",
    "        optimizer.zero_grad()\n",
    "        # retrieve text and no. of words\n",
    "\n",
    "        text, text_lengths = batch.reviewText\n",
    "        text, text_lengths =  text.to(device), text_lengths.to(device)\n",
    "\n",
    "        predictions = model(text)\n",
    "        loss = criterion(predictions, batch.overall)\n",
    "\n",
    "        acc = accuracy(predictions, batch.overall)\n",
    "\n",
    "        # perform backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    epoch_f1 = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.reviewText\n",
    "\n",
    "            predictions = model(text).squeeze(1)\n",
    "\n",
    "            loss = criterion(predictions, batch.overall)\n",
    "\n",
    "            acc = accuracy(predictions, batch.overall)\n",
    "            f1 = f1_loss(predictions.argmax(dim=1), batch.overall)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            epoch_f1 += f1.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), epoch_f1/len(iterator)\n",
    "\n",
    "\n",
    "def accuracy(probs, target):\n",
    "  winners = probs.argmax(dim=1)\n",
    "  corrects = (winners == target)\n",
    "  accuracy = corrects.sum().float() / float(target.size(0))\n",
    "  return accuracy"
   ],
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 3596/3596 [00:23<00:00, 154.20it/s]\n",
      "  0%|          | 0/3596 [00:00<?, ?it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 1.042 | Train Acc: 42.44%\n",
      "\t Val. Loss: 0.906 |  Val. Acc: 53.77%\n",
      "\t F1 score is 1.3534559601788922\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 3596/3596 [00:22<00:00, 161.60it/s]\n",
      "  0%|          | 0/3596 [00:00<?, ?it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.764 | Train Acc: 64.17%\n",
      "\t Val. Loss: 0.751 |  Val. Acc: 66.17%\n",
      "\t F1 score is 1.371495495049331\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 3596/3596 [00:22<00:00, 160.38it/s]\n",
      "  0%|          | 0/3596 [00:00<?, ?it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.540 | Train Acc: 76.96%\n",
      "\t Val. Loss: 0.737 |  Val. Acc: 69.83%\n",
      "\t F1 score is 1.4220948796952337\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 3596/3596 [00:22<00:00, 158.48it/s]\n",
      "  0%|          | 0/3596 [00:00<?, ?it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.378 | Train Acc: 84.15%\n",
      "\t Val. Loss: 0.949 |  Val. Acc: 69.64%\n",
      "\t F1 score is 1.4372555155670572\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 3596/3596 [00:22<00:00, 159.33it/s]\n",
      "  0%|          | 0/3596 [00:00<?, ?it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.332 | Train Acc: 86.26%\n",
      "\t Val. Loss: 1.061 |  Val. Acc: 69.95%\n",
      "\t F1 score is 1.4407364873711122\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 3596/3596 [00:22<00:00, 158.93it/s]\n",
      "  0%|          | 0/3596 [00:00<?, ?it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.303 | Train Acc: 87.60%\n",
      "\t Val. Loss: 1.138 |  Val. Acc: 71.05%\n",
      "\t F1 score is 1.4393183846986721\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 3596/3596 [00:22<00:00, 159.02it/s]\n",
      "  0%|          | 0/3596 [00:00<?, ?it/s]"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.281 | Train Acc: 88.50%\n",
      "\t Val. Loss: 1.204 |  Val. Acc: 70.61%\n",
      "\t F1 score is 1.4514214821265476\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 3596/3596 [00:22<00:00, 160.11it/s]\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "\tTrain Loss: 0.262 | Train Acc: 89.34%\n",
      "\t Val. Loss: 1.306 |  Val. Acc: 70.03%\n",
      "\t F1 score is 1.4607383524804836\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xxbA9oS_HRVk",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def f1_loss(y_true:torch.Tensor, y_pred:torch.Tensor, is_training=False) -> torch.Tensor:\n",
    "    '''Calculate F1 score. Can work with gpu tensors\n",
    "    \n",
    "    The original implmentation is written by Michal Haltuf on Kaggle.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        `ndim` == 1. 0 <= val <= 1\n",
    "    \n",
    "    Reference\n",
    "    ---------\n",
    "    - https://www.kaggle.com/rejpalcz/best-loss-function-for-f1-score-metric\n",
    "    - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score\n",
    "    - https://discuss.pytorch.org/t/calculating-precision-recall-and-f1-score-in-case-of-multi-label-classification/28265/6\n",
    "    \n",
    "    '''\n",
    "    assert y_true.ndim == 1\n",
    "    assert y_pred.ndim == 1 or y_pred.ndim == 2\n",
    "    \n",
    "    if y_pred.ndim == 2:\n",
    "        y_pred = y_pred.argmax(dim=1)\n",
    "        \n",
    "    \n",
    "    tp = (y_true * y_pred).sum().to(torch.float32)\n",
    "    tn = ((1 - y_true) * (1 - y_pred)).sum().to(torch.float32)\n",
    "    fp = ((1 - y_true) * y_pred).sum().to(torch.float32)\n",
    "    fn = (y_true * (1 - y_pred)).sum().to(torch.float32)\n",
    "    \n",
    "    epsilon = 1e-7\n",
    "    \n",
    "    precision = tp / (tp + fp + epsilon)\n",
    "    recall = tp / (tp + fn + epsilon)\n",
    "    \n",
    "    f1 = 2* (precision*recall) / (precision + recall + epsilon)\n",
    "    f1.requires_grad = is_training\n",
    "    return f1"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "az2uey3AX01Y",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import torchbearer\n",
    "from torchbearer import Trial\n",
    "from torch import optim\n",
    "\n",
    "hidden_size1 = 256\n",
    "hidden_size2 = 128\n",
    "hidden_size3 = 64\n",
    "batch_size = 50\n",
    "dropout_keep_prob = 0.5\n",
    "embedding_size = 300\n",
    "to_train = True\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "class MyIter:\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "    def __iter__(self):\n",
    "        for batch in self.it:\n",
    "            yield (batch.reviewText, batch.overall.unsqueeze(1))\n",
    "    def __len__(self):\n",
    "        return len(self.it)\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_ds, valid_ds, test_ds),\n",
    "    batch_size=batch_size,\n",
    "    device=device,\n",
    "    sort_key=lambda x: len(x.reviewText),\n",
    "    sort_within_batch=True)\n",
    "\n",
    "mlp_model = MLP(vocab_size, embedding_size, hidden_size1, hidden_size2, hidden_size3,  3, dropout_keep_prob, max_document_length)\n",
    "#train_iterator, valid_iterator, test_iterator = create_iterator(train_ds, valid_ds, test_ds, batch_size, device)\n",
    "\n",
    "\n",
    "# define the loss function and the optimiser\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimiser = optim.Adam(mlp_model.parameters(), lr=1e-4)\n",
    "run_train(8, mlp_model, train_iterator, valid_iterator, optimiser, loss_function, \"MLP\", device)\n",
    "# torchbearer_trial = Trial(mlp_model, optimiser, loss_function, metrics=['acc', 'loss']).to(device)\n",
    "# torchbearer_trial.with_generators(train_generator=MyIter(train_iterator), val_generator=MyIter(valid_iterator), test_generator=MyIter(test_iterator))\n",
    "# torchbearer_trial.run(epochs=5)\n",
    "# torchbearer_trial.predict()\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}