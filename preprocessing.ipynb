{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from autocorrect import Speller\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load Data\n",
    "\n",
    "- Read in the data and then shuffle"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data = pd.read_table('TripAdvisorUKRestaurant-max_MF.txt', names=[\"rating\",\"review\"])\n",
    "data = data.sample(frac=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Helper function to print tokens in a sentence \n",
    "\n",
    "def print_tokens(doc):\n",
    "    for token in doc:\n",
    "        token_text = token.text\n",
    "        token_pos = token.pos_\n",
    "        token_dep = token.dep_\n",
    "        token_vec = token.vector\n",
    "        print(\"{:<12}{:<10}{:<10}\".format(token_text, token_pos, token_dep))\n",
    "    print(token.vector)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialise SpaCy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You need to download the spacy model with:\n",
    "\n",
    "`python -m spacy download en_core_web_md`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clean Text\n",
    "\n",
    "1. Pronouns are removed from the text - lemmtaisation\n",
    "2. Then stopwords and punctuation are removed\n",
    "3. Then the removal of spaces and numbers and undetected punctuation\n",
    "4. Removal of URLS and Emails\n",
    "5. The whole sentence is then spell checked and corrected"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def tokenizer(sentence):\n",
    "    punctuation = string.punctuation\n",
    "    stopwords = list(STOP_WORDS)\n",
    "    filterTokens = [ word for word in sentence if word.lemma_ != \"-PRON-\" ]\n",
    "    filterTokens = [ word for word in filterTokens if word.text not in stopwords and word.text not in punctuation ]\n",
    "    filterTokens = [ word for word in filterTokens if word.pos_ not in [\"SPACE\",\"PUNCT\",\"NUM\"]]\n",
    "    filterTokens = [ word for word in filterTokens if (not word.like_url or not word.like_email) ]\n",
    "    return filterTokens\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def clean_text(num_entries):\n",
    "    spell = Speller(lang='en')\n",
    "    text = []\n",
    "    for review in tqdm(data[0:num_entries].review):\n",
    "        doc = nlp(review)\n",
    "        clean_token = tokenizer(doc)\n",
    "        sentence = ' '.join([x.text.lower() for x in clean_token])\n",
    "        sentence = spell(sentence)\n",
    "        text.append(sentence)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clean all the text and put into a list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "100%|██████████| 1000/1000 [01:40<00:00, 10.00it/s]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "text = clean_text()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}