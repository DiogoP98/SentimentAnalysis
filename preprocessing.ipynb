{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import preprocessor as p\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "- Read in the data and then shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "file_num = 0\n",
    "df = pd.read_csv(f\"{file_num}.csv\",keep_default_na=False)\n",
    "df = df[~df['reviewText'].str.contains(\"\\.jpg|\\.png|\\.jpeg|\\.tiff|\\.gif|\\.bmp|\\.heif\", regex=True, na=False)]\n",
    "old = df.copy()\n",
    "text = df.reviewText\n",
    "num_entries = len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initial Data cleaning\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def tweet_clean(num_entries):\n",
    "    for index, review in tqdm(enumerate(text[0:num_entries])):\n",
    "        clean_text = p.clean(review)\n",
    "        df.reviewText[index] = clean_text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#tweet_clean(num_entries)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Helper function to print tokens in a sentence \n",
    "\n",
    "def print_tokens(doc):\n",
    "    for token in doc:\n",
    "        token_text = token.text\n",
    "        token_pos = token.pos_\n",
    "        token_dep = token.dep_\n",
    "        token_vec = token.vector\n",
    "        print(\"{:<12}{:<10}{:<10}\".format(token_text, token_pos, token_dep))\n",
    "    print(token.vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to download the spacy model with:\n",
    "\n",
    "python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Text\n",
    "\n",
    "1. Pronouns are removed from the text - lemmtaisation\n",
    "2. Then stopwords and punctuation are removed\n",
    "3. Then the removal of spaces and numbers and undetected punctuation\n",
    "4. Removal of URLS and Emails\n",
    "5. The whole sentence is then spell checked and corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def tokenizer(sentence):\n",
    "    punctuation = string.punctuation\n",
    "    stopwords = list(STOP_WORDS)\n",
    "    filterTokens = [ word for word in sentence if word.lemma_ != \"-PRON-\" ]\n",
    "    filterTokens = [ word for word in filterTokens if word.text not in stopwords and word.text not in punctuation ]\n",
    "    filterTokens = [ word for word in filterTokens if word.pos_ not in [\"SPACE\",\"PUNCT\",\"NUM\"]]\n",
    "    filterTokens = [ word for word in filterTokens if not word.like_email ]\n",
    "    return filterTokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(num_entries):\n",
    "    for index, review in tqdm(enumerate(text[0:num_entries])):\n",
    "        doc = nlp(review)\n",
    "        clean_token = tokenizer(doc)\n",
    "        sentence = ' '.join([x.text.lower() for x in clean_token])\n",
    "        df.reviewText[index] = sentence\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean all the text and put into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A/home/alex/anaconda3/envs/deepLearning/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "\n",
      "2it [00:00, 14.66it/s]\u001b[A\n",
      "6it [00:00, 17.47it/s]\u001b[A\n",
      "9it [00:00, 19.43it/s]\u001b[A\n",
      "13it [00:00, 22.52it/s]\u001b[A\n",
      "16it [00:00, 22.92it/s]\u001b[A\n",
      "20it [00:00, 23.91it/s]\u001b[A\n",
      "23it [00:00, 24.21it/s]\u001b[A\n",
      "26it [00:00, 24.92it/s]\u001b[A\n",
      "29it [00:01, 23.93it/s]\u001b[A\n",
      "33it [00:01, 26.86it/s]\u001b[A\n",
      "36it [00:01, 22.71it/s]\u001b[A\n",
      "40it [00:01, 24.15it/s]\u001b[A\n",
      "43it [00:01, 22.99it/s]\u001b[A\n",
      "46it [00:01, 22.56it/s]\u001b[A\n",
      "49it [00:01, 22.19it/s]\u001b[A\n",
      "53it [00:02, 24.66it/s]\u001b[A\n",
      "56it [00:02, 24.54it/s]\u001b[A\n",
      "59it [00:02, 25.57it/s]\u001b[A\n",
      "62it [00:02, 22.47it/s]\u001b[A\n",
      "66it [00:02, 24.24it/s]\u001b[A\n",
      "69it [00:02, 24.17it/s]\u001b[A\n",
      "72it [00:02, 20.75it/s]\u001b[A\n",
      "75it [00:03, 20.79it/s]\u001b[A\n",
      "78it [00:03, 21.94it/s]\u001b[A\n",
      "81it [00:03, 22.73it/s]\u001b[A\n",
      "84it [00:03, 21.73it/s]\u001b[A\n",
      "87it [00:03, 22.69it/s]\u001b[A\n",
      "90it [00:03, 23.44it/s]\u001b[A\n",
      "93it [00:03, 23.24it/s]\u001b[A\n",
      "96it [00:04, 20.96it/s]\u001b[A\n",
      "99it [00:04, 21.59it/s]\u001b[A\n",
      "102it [00:04, 22.46it/s]\u001b[A\n",
      "106it [00:04, 22.29it/s]\u001b[A\n",
      "109it [00:04, 21.98it/s]\u001b[A\n",
      "112it [00:04, 22.99it/s]\u001b[A\n",
      "115it [00:04, 21.51it/s]\u001b[A\n",
      "118it [00:05, 22.18it/s]\u001b[A\n",
      "122it [00:05, 24.86it/s]\u001b[A\n",
      "125it [00:05, 21.49it/s]\u001b[A\n",
      "128it [00:05, 19.20it/s]\u001b[A\n",
      "132it [00:05, 21.44it/s]\u001b[A\n",
      "135it [00:05, 23.29it/s]\u001b[A\n",
      "138it [00:05, 24.13it/s]\u001b[A\n",
      "141it [00:05, 25.31it/s]\u001b[A\n",
      "144it [00:06, 23.35it/s]\u001b[A\n",
      "147it [00:06, 24.14it/s]\u001b[A\n",
      "150it [00:06, 22.12it/s]\u001b[A\n",
      "154it [00:06, 25.02it/s]\u001b[A\n",
      "157it [00:06, 25.82it/s]\u001b[A\n",
      "160it [00:06, 26.75it/s]\u001b[A\n",
      "163it [00:06, 27.54it/s]\u001b[A\n",
      "166it [00:06, 26.05it/s]\u001b[A\n",
      "170it [00:07, 28.22it/s]\u001b[A\n",
      "174it [00:07, 30.20it/s]\u001b[A\n",
      "178it [00:07, 30.28it/s]\u001b[A\n",
      "182it [00:07, 31.03it/s]\u001b[A\n",
      "186it [00:07, 31.43it/s]\u001b[A\n",
      "190it [00:07, 28.57it/s]\u001b[A\n",
      "194it [00:07, 30.24it/s]\u001b[A\n",
      "198it [00:07, 30.86it/s]\u001b[A\n",
      "202it [00:08, 31.70it/s]\u001b[A\n",
      "206it [00:08, 30.74it/s]\u001b[A\n",
      "210it [00:08, 32.15it/s]\u001b[A\n",
      "214it [00:08, 29.35it/s]\u001b[A\n",
      "218it [00:08, 31.41it/s]\u001b[A\n",
      "222it [00:08, 31.65it/s]\u001b[A\n",
      "226it [00:08, 26.48it/s]\u001b[A\n",
      "230it [00:09, 28.41it/s]\u001b[A\n",
      "234it [00:09, 26.06it/s]\u001b[A\n",
      "237it [00:09, 26.21it/s]\u001b[A\n",
      "241it [00:09, 28.45it/s]\u001b[A\n",
      "244it [00:09, 24.42it/s]\u001b[A\n",
      "247it [00:09, 24.13it/s]\u001b[A\n",
      "251it [00:09, 26.21it/s]\u001b[A\n",
      "255it [00:09, 27.86it/s]\u001b[A\n",
      "258it [00:10, 26.27it/s]\u001b[A\n",
      "261it [00:10, 26.93it/s]\u001b[A\n",
      "265it [00:10, 28.83it/s]\u001b[A\n",
      "268it [00:10, 28.87it/s]\u001b[A\n",
      "271it [00:10, 24.82it/s]\u001b[A\n",
      "275it [00:10, 27.90it/s]\u001b[A\n",
      "279it [00:10, 27.18it/s]\u001b[A\n",
      "282it [00:10, 27.08it/s]\u001b[A\n",
      "286it [00:11, 29.32it/s]\u001b[A\n",
      "290it [00:11, 29.45it/s]\u001b[A\n",
      "294it [00:11, 29.05it/s]\u001b[A\n",
      "298it [00:11, 30.89it/s]\u001b[A\n",
      "302it [00:11, 28.75it/s]\u001b[A\n",
      "305it [00:11, 27.22it/s]\u001b[A\n",
      "308it [00:11, 27.37it/s]\u001b[A\n",
      "311it [00:11, 27.44it/s]\u001b[A\n",
      "314it [00:12, 26.87it/s]\u001b[A\n",
      "318it [00:12, 29.38it/s]\u001b[A\n",
      "322it [00:12, 29.73it/s]\u001b[A\n",
      "326it [00:12, 29.46it/s]\u001b[A\n",
      "330it [00:12, 30.90it/s]\u001b[A\n",
      "334it [00:12, 29.41it/s]\u001b[A\n",
      "337it [00:12, 29.36it/s]\u001b[A\n",
      "341it [00:12, 30.55it/s]\u001b[A\n",
      "345it [00:13, 27.89it/s]\u001b[A\n",
      "348it [00:13, 27.65it/s]\u001b[A\n",
      "352it [00:13, 28.59it/s]\u001b[A\n",
      "356it [00:13, 30.21it/s]\u001b[A\n",
      "360it [00:13, 28.74it/s]\u001b[A\n",
      "363it [00:13, 24.74it/s]\u001b[A\n",
      "366it [00:13, 24.99it/s]\u001b[A\n",
      "370it [00:14, 27.32it/s]\u001b[A\n",
      "374it [00:14, 28.29it/s]\u001b[A\n",
      "378it [00:14, 30.04it/s]\u001b[A\n",
      "382it [00:14, 28.35it/s]\u001b[A\n",
      "385it [00:14, 27.62it/s]\u001b[A\n",
      "389it [00:14, 29.66it/s]\u001b[A\n",
      "393it [00:14, 26.54it/s]\u001b[A\n",
      "396it [00:15, 23.68it/s]\u001b[A\n",
      "399it [00:15, 24.28it/s]\u001b[A\n",
      "403it [00:15, 27.04it/s]\u001b[A\n",
      "406it [00:15, 26.98it/s]\u001b[A\n",
      "410it [00:15, 28.30it/s]\u001b[A\n",
      "414it [00:15, 30.06it/s]\u001b[A\n",
      "418it [00:15, 30.82it/s]\u001b[A\n",
      "422it [00:15, 29.02it/s]\u001b[A\n",
      "425it [00:15, 26.79it/s]\u001b[A\n",
      "428it [00:16, 18.49it/s]\u001b[A\n",
      "431it [00:16, 19.32it/s]\u001b[A\n",
      "434it [00:16, 20.30it/s]\u001b[A\n",
      "437it [00:16, 20.88it/s]\u001b[A\n",
      "440it [00:16, 21.29it/s]\u001b[A\n",
      "443it [00:16, 22.44it/s]\u001b[A\n",
      "446it [00:17, 19.98it/s]\u001b[A\n",
      "449it [00:17, 21.90it/s]\u001b[A\n",
      "453it [00:17, 24.91it/s]\u001b[A\n",
      "457it [00:17, 26.23it/s]\u001b[A\n",
      "460it [00:17, 25.34it/s]\u001b[A\n",
      "463it [00:17, 26.54it/s]\u001b[A\n",
      "467it [00:17, 27.17it/s]\u001b[A\n",
      "471it [00:17, 28.43it/s]\u001b[A"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-00ca84ee62ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_entries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-4d561f36f5d3>\u001b[0m in \u001b[0;36mclean_text\u001b[0;34m(num_entries)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mclean_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclean_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreviewText\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepLearning/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcacher_needs_updating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_with_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepLearning/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[0;34m(self, clear, verify_is_copy)\u001b[0m\n\u001b[1;32m   3280\u001b[0m                 \u001b[0;31m#  case where it will raise.  (Uh, not clear why)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3282\u001b[0;31m                     \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cache_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcacher\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3283\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3284\u001b[0m                     \u001b[0;31m# ref._data.setitem can raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepLearning/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_maybe_cache_changed\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   3239\u001b[0m         \"\"\"The object has called back to us saying maybe it has changed.\n\u001b[1;32m   3240\u001b[0m         \"\"\"\n\u001b[0;32m-> 3241\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3243\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepLearning/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mblk_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m                 \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                 \u001b[0munfit_mgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepLearning/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, locs, values)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \"\"\"\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "clean_text(num_entries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the cleaned data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.to_csv(f'kindle_reviews_cleaned_{file_num}.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Just to test \n",
    "\n",
    "# twitter - 62 ops/sec - 3 hours\n",
    "# spacy clean - 30 ops/sec - 8 hours\n",
    "\n",
    "# 11 hours\n",
    "\n",
    "# 6 threads = 11/6 = 1.86 hours\n",
    "\n",
    "df_2 = pd.read_csv(\"data_split/kindle_reviews_cleaned_0.csv\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "# def index_marks(nrows, chunk_size):\n",
    "#     return range(chunk_size, math.ceil(nrows / chunk_size) * chunk_size, chunk_size)\n",
    "# \n",
    "# \n",
    "# def split(dfm, chunk_size):\n",
    "#     indices = index_marks(dfm.shape[0], chunk_size)\n",
    "#     return np.split(dfm, indices)\n",
    "# \n",
    "# chunks = split(df, 163765)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# for inx, c in enumerate(chunks):\n",
    "#     c.to_csv(f\"data_split/{inx}.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}