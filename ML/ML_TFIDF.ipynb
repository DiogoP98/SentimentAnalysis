{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "ML_TFIDF.ipynb",
   "provenance": [],
   "toc_visible": true,
   "machine_shape": "hm"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "KoghZU9Zu9EY",
    "colab_type": "code",
    "outputId": "e0eeeaae-d929-4116-a16c-26898a84ec9c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.pipeline import Pipeline as imPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.base import TransformerMixin\n"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "hKSF3RsZu9EY",
    "colab_type": "code",
    "outputId": "90816d9e-a67d-4887-8d50-a7a732fcb4e1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    }
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# root_path = \"/content/drive/My Drive/notebooks\"\n",
    "# # For Google colab only\n",
    "\n",
    "df = pd.read_csv(f\"../kindle_reviews_2million.csv\")\n",
    "df = df[df['reviewText'].notna()]\n",
    "df = df[~df['reviewText'].str.contains(\".jpg|.png|.jpeg|.tiff|.gif|.bmp|.heif\", regex=True, na=False)]"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "bsMDuk3Eu9F8",
    "colab_type": "text"
   },
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "hT55436Ju9F8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "### Convert to a two class problem -  optional\n",
    "\n",
    "# df = df[df['overall'] != 3]\n",
    "# df['overall'] = np.where(df['overall'] > 3, 1, 0)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ryK1dwGZu9F8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "X = df.reviewText.values\n",
    "y = df.overall.values"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "LcsFqUOlu9F8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "num = len(df)\n",
    "X, y  = X[:num], y[:num]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "WZjcShq9u9F8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "MhAPlC6Cu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def train_predict(pipline):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    score = classification_report(y_test, y_pred)\n",
    "    #score = roc_auc_score(y_test, y_pred, average=\"macro\")\n",
    "    #print('AUC: ', roc_auc_score(y_test, y_pred))\n",
    "    print(score)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    },
    "id": "OrHKgr4Qu9Hg",
    "colab_type": "text"
   },
   "source": [
    "Vectorizers\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Uq3xzk7ru9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "count_vectoriser = Pipeline([\n",
    "                ('countVectoriser', CountVectorizer())\n",
    "            ])\n",
    "\n",
    "tfidf_vectoriser = Pipeline([\n",
    "                ('tfidfVectoriser', TfidfVectorizer(stop_words=STOP_WORDS\n",
    "                                                    ))\n",
    "            ])\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "kPj6SCeBu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def make_balance_pipe(steps):\n",
    "\n",
    "    \"\"\"Used to make a pipeline using imblearn\"\"\"    \n",
    "\n",
    "    x = list(range(len(steps)))\n",
    "    pipeline= [(str(x),y) for x,y in zip(x,steps)]\n",
    "\n",
    "    return imPipeline(pipeline)\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brx01xkqaW70",
    "colab_type": "text"
   },
   "source": [
    "### Stantard Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "h0UeIUoqu9Hg",
    "colab_type": "text"
   },
   "source": [
    "Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "KLqrDXvZu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "naive_bayes = Pipeline([\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', naive_bayes)\n",
    "])\n",
    "\n",
    "# pipeline = make_balance_pipe([TfidfVectorizer(),\n",
    "#                               RandomUnderSampler(),\n",
    "#                               MultinomialNB()])\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "NIZko0QUu9Hg",
    "colab_type": "code",
    "outputId": "f8c07aca-0fae-4ad9-b1aa-9f7ac2c2ef98",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    }
   },
   "source": [
    "train_predict(pipeline)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58    163059\n",
      "           1       0.42      0.46      0.44    163100\n",
      "           2       0.46      0.39      0.42    162996\n",
      "           3       0.47      0.43      0.45    161668\n",
      "           4       0.63      0.72      0.67    161597\n",
      "\n",
      "    accuracy                           0.51    812420\n",
      "   macro avg       0.51      0.52      0.51    812420\n",
      "weighted avg       0.51      0.51      0.51    812420\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MNW6uGPigGg",
    "colab_type": "text"
   },
   "source": [
    "Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Vj8JZGvhii7w",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ezR8X1oyikmA",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "g_naive_bayes = Pipeline([\n",
    "    ('classifier', GaussianNB()),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('to_dense', DenseTransformer()), \n",
    "    ('classifier', g_naive_bayes)\n",
    "])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mFRyF6E8ivSY",
    "colab_type": "code",
    "outputId": "e3b24fed-64d5-4530-b091-c505ab4b04bb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    }
   },
   "source": [
    "train_predict(pipeline)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsf3G4Ohi7w0",
    "colab_type": "text"
   },
   "source": [
    "Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QH6ndCOXi9kc",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uW9WUixUjApU",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "QDA = Pipeline([\n",
    "    ('classifier', QuadraticDiscriminantAnalysis()),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('to_dense', DenseTransformer()), \n",
    "    ('classifier', QDA)\n",
    "])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cTGCRpeDjr6E",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "train_predict(pipeline)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    },
    "id": "LjDB-CiGu9Hg",
    "colab_type": "text"
   },
   "source": [
    "Max Entropy"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "7pin5oYJu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "YnsfsTlVu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "max_ent = Pipeline([\n",
    "    ('classifier', LogisticRegression(penalty='l2', C=1.0)),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', max_ent)\n",
    "])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "3RfVC1Yzu9Hg",
    "colab_type": "code",
    "outputId": "dc4475f1-a6f8-4745-919f-d8e1ff780e90",
    "colab": {}
   },
   "source": [
    "train_predict(pipeline)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/deepLearning/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/alex/anaconda3/envs/deepLearning/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.62      0.61    163059\n",
      "           1       0.45      0.46      0.45    163100\n",
      "           2       0.47      0.42      0.44    162996\n",
      "           3       0.50      0.49      0.49    161668\n",
      "           4       0.67      0.71      0.69    161597\n",
      "\n",
      "    accuracy                           0.54    812420\n",
      "   macro avg       0.54      0.54      0.54    812420\n",
      "weighted avg       0.54      0.54      0.54    812420\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "PfHaBUJUu9Hg",
    "colab_type": "text"
   },
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "-8wx5ysOu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# params={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}\n",
    "# logistic_regression = Pipeline([\n",
    "#     ('classifier', GridSearchCV(LogisticRegression(), params, cv=10)),\n",
    "# ])\n",
    "\n",
    "logistic_regression = Pipeline([\n",
    "    ('classifier', LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', logistic_regression)\n",
    "])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "1Zy17E72u9Hg",
    "colab_type": "code",
    "outputId": "1c11de06-f137-46f6-a56e-31a589e60400",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    }
   },
   "source": [
    "train_predict(pipeline)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.64      0.62    163059\n",
      "           1       0.46      0.44      0.45    163100\n",
      "           2       0.48      0.44      0.46    162996\n",
      "           3       0.51      0.52      0.51    161668\n",
      "           4       0.69      0.73      0.71    161597\n",
      "\n",
      "    accuracy                           0.55    812420\n",
      "   macro avg       0.55      0.55      0.55    812420\n",
      "weighted avg       0.55      0.55      0.55    812420\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1FMt2Evc9ag",
    "colab_type": "text"
   },
   "source": [
    " Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ObhcwhKifZZU",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wdBW7C0HdBfc",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "decision_tree = Pipeline([\n",
    "    ('classifier', DecisionTreeClassifier(),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', decision_tree)\n",
    "])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "1yA0yrU-u9Hg",
    "colab_type": "text"
   },
   "source": [
    "### Bagging Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "_m6mNSsfu9Hg",
    "colab_type": "text"
   },
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "R_1d7-Lbu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# random_forest = Pipeline([\n",
    "#     ('classifier', RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = random_grid,\n",
    "#                                       n_iter = 100, cv = 3, verbose=2, random_state=42,\n",
    "#                                       n_jobs = -1)),\n",
    "# ])\n",
    "\n",
    "random_forest = Pipeline([\n",
    "    ('classifier', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', random_forest)\n",
    "])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "C_-o8KD7u9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "train_predict(pipeline)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "rdPWKCRCu9Hg",
    "colab_type": "text"
   },
   "source": [
    "### Boosting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "5F5Imj-Iu9Hg",
    "colab_type": "text"
   },
   "source": [
    "XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "loGx-6NOu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# !wget https://s3-us-west-2.amazonaws.com/xgboost-wheels/xgboost-0.81-py2.py3-none-manylinux1_x86_64.whl\n",
    "# !pip uninstall xgboost --yes\n",
    "# !pip install xgboost-0.81-py2.py3-none-manylinux1_x86_64.whl\n",
    "\n",
    "# For Google Colab Only"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "02VNoY6ku9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from xgboost import XGBClassifier"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "aG-WP81-u9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "params = {\n",
    " \"num_class\": 5,\n",
    " \"objective\": \"multi:softmax\"}\n",
    "\n",
    "xg_boost = Pipeline([\n",
    "    ('classifier', XGBClassifier(**params))\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', xg_boost)\n",
    "])\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "nC45fzhtu9Hg",
    "colab_type": "code",
    "outputId": "62ec3e73-9577-4a2a-edd4-eb98de44ab8c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    }
   },
   "source": [
    "train_predict(pipeline)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    },
    "id": "_ImBrPx9u9Hg",
    "colab_type": "text"
   },
   "source": [
    "AdaBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "rBw3bi62u9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "dXZXdSYFu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "adaBoost = Pipeline([\n",
    "    ('classifier', AdaBoostClassifier()),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', adaBoost)\n",
    "])\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "tLpkO8nEu9Hg",
    "colab_type": "code",
    "outputId": "30f83c56-bf3a-46fc-da2b-1a37b6f540be",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    }
   },
   "source": [
    "train_predict(pipeline)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.67      0.49    163059\n",
      "           1       0.39      0.21      0.27    163100\n",
      "           2       0.38      0.25      0.31    162996\n",
      "           3       0.37      0.36      0.36    161668\n",
      "           4       0.55      0.62      0.58    161597\n",
      "\n",
      "    accuracy                           0.42    812420\n",
      "   macro avg       0.42      0.42      0.40    812420\n",
      "weighted avg       0.42      0.42      0.40    812420\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "fILFPVbOu9Hg",
    "colab_type": "text"
   },
   "source": [
    "\n",
    "Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "CdUJxEzvu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "GEqjRG0mu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "models = [\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier()\n",
    "]\n",
    "\n",
    "m_names = [m.__class__.__name__ for m in models]\n",
    "\n",
    "models = list(zip(m_names, models))\n",
    "vc = VotingClassifier(estimators=models)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "K7rY3rifu9Hg",
    "colab_type": "text"
   },
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "lXbzlMrzu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "votingClassifier = Pipeline([\n",
    "    ('classifier', vc),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', votingClassifier)\n",
    "])\n",
    "\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "W-WkjA5eu9Hg",
    "colab_type": "code",
    "outputId": "ac548d25-8794-4a74-f8b2-3fdd3e5359b5",
    "colab": {}
   },
   "source": [
    "train_predict(pipeline)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/deepLearning/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ],
     "name": "stderr"
    }
   ]
  }
 ]
}