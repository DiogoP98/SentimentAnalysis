{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "ML_TFIDF.ipynb",
   "provenance": [],
   "toc_visible": true,
   "machine_shape": "hm"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "KoghZU9Zu9EY",
    "colab_type": "code",
    "outputId": "e0eeeaae-d929-4116-a16c-26898a84ec9c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.pipeline import Pipeline as imPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/alex/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/alex/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/alex/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/alex/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/alex/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "hKSF3RsZu9EY",
    "colab_type": "code",
    "outputId": "90816d9e-a67d-4887-8d50-a7a732fcb4e1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    }
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# root_path = \"/content/drive/My Drive/notebooks\"\n",
    "# # For Google colab only\n",
    "\n",
    "df = pd.read_csv(f\"../new_clean_sm_100000.csv\")\n",
    "df = df[df['reviewText'].notna()]\n",
    "df = df[~df['reviewText'].str.contains(\".jpg|.png|.jpeg|.tiff|.gif|.bmp|.heif\", regex=True, na=False)]"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "bsMDuk3Eu9F8",
    "colab_type": "text"
   },
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "hT55436Ju9F8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "### Convert to a two class problem -  optional\n",
    "\n",
    "df = df[df['overall'] != 2]\n",
    "df = df[df['overall'] != 4]\n",
    "df.loc[df['overall'] == 1, 'overall'] = 0\n",
    "df.loc[df['overall'] == 3, 'overall'] = 1\n",
    "df.loc[df['overall'] == 5, 'overall'] = 2"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "ryK1dwGZu9F8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "X = df.reviewText.values\n",
    "y = df.overall.values"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "LcsFqUOlu9F8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "num = len(df)\n",
    "X, y  = X[:num], y[:num]\n",
    "# le = LabelEncoder()\n",
    "# y = le.fit_transform(y)"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "WZjcShq9u9F8",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "MhAPlC6Cu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def train_predict(pipline):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    score = classification_report(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    #score = roc_auc_score(y_test, y_pred, average=\"macro\")\n",
    "    #print('AUC: ', roc_auc_score(y_test, y_pred))\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(score)\n",
    "    print(f\"f1 score is {f1}, accuracy is {accuracy}\")"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    },
    "id": "OrHKgr4Qu9Hg",
    "colab_type": "text"
   },
   "source": [
    "Vectorizers\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Uq3xzk7ru9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "count_vectoriser = Pipeline([\n",
    "                ('countVectoriser', CountVectorizer())\n",
    "            ])\n",
    "\n",
    "tfidf_vectoriser = Pipeline([\n",
    "                ('tfidfVectoriser', TfidfVectorizer(stop_words=STOP_WORDS\n",
    "                                                    ))\n",
    "            ])\n",
    "\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()"
   ],
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "kPj6SCeBu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "def make_balance_pipe(steps):\n",
    "\n",
    "    \"\"\"Used to make a pipeline using imblearn\"\"\"    \n",
    "\n",
    "    x = list(range(len(steps)))\n",
    "    pipeline= [(str(x),y) for x,y in zip(x,steps)]\n",
    "\n",
    "    return imPipeline(pipeline)\n"
   ],
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brx01xkqaW70",
    "colab_type": "text"
   },
   "source": [
    "### Stantard Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "h0UeIUoqu9Hg",
    "colab_type": "text"
   },
   "source": [
    "Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "KLqrDXvZu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "naive_bayes = Pipeline([\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', naive_bayes)\n",
    "])\n",
    "\n",
    "# pipeline = make_balance_pipe([TfidfVectorizer(),\n",
    "#                               RandomUnderSampler(),\n",
    "#                               MultinomialNB()])\n"
   ],
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "NIZko0QUu9Hg",
    "colab_type": "code",
    "outputId": "f8c07aca-0fae-4ad9-b1aa-9f7ac2c2ef98",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    }
   },
   "source": [
    "train_predict(pipeline)"
   ],
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/deepLearning/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.77      0.76     32880\n",
      "         1.0       0.67      0.67      0.67     32922\n",
      "         2.0       0.82      0.82      0.82     33069\n",
      "\n",
      "    accuracy                           0.75     98871\n",
      "   macro avg       0.75      0.75      0.75     98871\n",
      "weighted avg       0.75      0.75      0.75     98871\n",
      "\n",
      "f1 score is 0.7512440533658252, accuracy is 0.7511201464534596\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MNW6uGPigGg",
    "colab_type": "text"
   },
   "source": [
    "Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Vj8JZGvhii7w",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ezR8X1oyikmA",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "g_naive_bayes = Pipeline([\n",
    "    ('classifier', GaussianNB()),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('to_dense', DenseTransformer()), \n",
    "    ('classifier', g_naive_bayes)\n",
    "])"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mFRyF6E8ivSY",
    "colab_type": "code",
    "outputId": "e3b24fed-64d5-4530-b091-c505ab4b04bb",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    }
   },
   "source": [
    "train_predict(pipeline)"
   ],
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/deepLearning/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.21      0.21      6581\n",
      "           1       0.21      0.23      0.22      6641\n",
      "           2       0.20      0.19      0.20      6575\n",
      "           3       0.20      0.19      0.19      6573\n",
      "           4       0.21      0.21      0.21      6572\n",
      "\n",
      "    accuracy                           0.21     32942\n",
      "   macro avg       0.21      0.21      0.21     32942\n",
      "weighted avg       0.21      0.21      0.21     32942\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsf3G4Ohi7w0",
    "colab_type": "text"
   },
   "source": [
    "Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QH6ndCOXi9kc",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uW9WUixUjApU",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "QDA = Pipeline([\n",
    "    ('classifier', QuadraticDiscriminantAnalysis()),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('to_dense', DenseTransformer()), \n",
    "    ('classifier', QDA)\n",
    "])"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cTGCRpeDjr6E",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "train_predict(pipeline)"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.23      0.22      6581\n",
      "           1       0.20      0.20      0.20      6641\n",
      "           2       0.20      0.19      0.20      6575\n",
      "           3       0.21      0.18      0.19      6573\n",
      "           4       0.22      0.22      0.22      6572\n",
      "\n",
      "    accuracy                           0.21     32942\n",
      "   macro avg       0.21      0.21      0.21     32942\n",
      "weighted avg       0.21      0.21      0.21     32942\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    },
    "id": "LjDB-CiGu9Hg",
    "colab_type": "text"
   },
   "source": [
    "Max Entropy"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "7pin5oYJu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "YnsfsTlVu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "max_ent = Pipeline([\n",
    "    ('classifier', LogisticRegression(penalty='l2', C=1.0)),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', max_ent)\n",
    "])"
   ],
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "3RfVC1Yzu9Hg",
    "colab_type": "code",
    "outputId": "dc4475f1-a6f8-4745-919f-d8e1ff780e90",
    "colab": {}
   },
   "source": [
    "train_predict(pipeline)"
   ],
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/deepLearning/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.21      0.20      0.20      6581\n",
      "         2.0       0.20      0.20      0.20      6641\n",
      "         3.0       0.20      0.20      0.20      6575\n",
      "         4.0       0.20      0.19      0.19      6573\n",
      "         5.0       0.21      0.23      0.22      6572\n",
      "\n",
      "    accuracy                           0.21     32942\n",
      "   macro avg       0.20      0.21      0.20     32942\n",
      "weighted avg       0.20      0.21      0.20     32942\n",
      "\n",
      "f1 score is 0.20494872650661872, accuracy is 0.2051484427175035\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "PfHaBUJUu9Hg",
    "colab_type": "text"
   },
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "-8wx5ysOu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# params={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}\n",
    "# logistic_regression = Pipeline([\n",
    "#     ('classifier', GridSearchCV(LogisticRegression(), params, cv=10)),\n",
    "# ])\n",
    "\n",
    "logistic_regression = Pipeline([\n",
    "    ('classifier', LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', logistic_regression)\n",
    "])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "1Zy17E72u9Hg",
    "colab_type": "code",
    "outputId": "1c11de06-f137-46f6-a56e-31a589e60400",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    }
   },
   "source": [
    "train_predict(pipeline)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.64      0.62    163059\n",
      "           1       0.46      0.44      0.45    163100\n",
      "           2       0.48      0.44      0.46    162996\n",
      "           3       0.51      0.52      0.51    161668\n",
      "           4       0.69      0.73      0.71    161597\n",
      "\n",
      "    accuracy                           0.55    812420\n",
      "   macro avg       0.55      0.55      0.55    812420\n",
      "weighted avg       0.55      0.55      0.55    812420\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1FMt2Evc9ag",
    "colab_type": "text"
   },
   "source": [
    " Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ObhcwhKifZZU",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wdBW7C0HdBfc",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "decision_tree = Pipeline([\n",
    "    ('classifier', DecisionTreeClassifier()),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', decision_tree)\n",
    "])"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.20      0.20      0.20      6581\n",
      "         2.0       0.21      0.21      0.21      6641\n",
      "         3.0       0.19      0.19      0.19      6575\n",
      "         4.0       0.20      0.20      0.20      6573\n",
      "         5.0       0.20      0.20      0.20      6572\n",
      "\n",
      "    accuracy                           0.20     32942\n",
      "   macro avg       0.20      0.20      0.20     32942\n",
      "weighted avg       0.20      0.20      0.20     32942\n",
      "\n",
      "f1 score is 0.2010128486000343, accuracy is 0.2010199745006375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_predict(pipeline)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "1yA0yrU-u9Hg",
    "colab_type": "text"
   },
   "source": [
    "### Bagging Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "_m6mNSsfu9Hg",
    "colab_type": "text"
   },
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "R_1d7-Lbu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# random_forest = Pipeline([\n",
    "#     ('classifier', RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = random_grid,\n",
    "#                                       n_iter = 100, cv = 3, verbose=2, random_state=42,\n",
    "#                                       n_jobs = -1)),\n",
    "# ])\n",
    "\n",
    "random_forest = Pipeline([\n",
    "    ('classifier', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', random_forest)\n",
    "])"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "C_-o8KD7u9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "train_predict(pipeline)"
   ],
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.20      0.21      0.20      6581\n",
      "         2.0       0.21      0.20      0.20      6641\n",
      "         3.0       0.20      0.20      0.20      6575\n",
      "         4.0       0.20      0.20      0.20      6573\n",
      "         5.0       0.20      0.20      0.20      6572\n",
      "\n",
      "    accuracy                           0.20     32942\n",
      "   macro avg       0.20      0.20      0.20     32942\n",
      "weighted avg       0.20      0.20      0.20     32942\n",
      "\n",
      "f1 score is 0.2028050536791965, accuracy is 0.20281100115354259\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "rdPWKCRCu9Hg",
    "colab_type": "text"
   },
   "source": [
    "### Boosting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "5F5Imj-Iu9Hg",
    "colab_type": "text"
   },
   "source": [
    "XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "loGx-6NOu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# !wget https://s3-us-west-2.amazonaws.com/xgboost-wheels/xgboost-0.81-py2.py3-none-manylinux1_x86_64.whl\n",
    "# !pip uninstall xgboost --yes\n",
    "# !pip install xgboost-0.81-py2.py3-none-manylinux1_x86_64.whl\n",
    "\n",
    "# For Google Colab Only"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "02VNoY6ku9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from xgboost import XGBClassifier"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "aG-WP81-u9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "params = {\n",
    " \"num_class\": 5,\n",
    " \"objective\": \"multi:softmax\",\n",
    "\"n_jobs\":-1}\n",
    "\n",
    "xg_boost = Pipeline([\n",
    "    ('classifier', XGBClassifier(**params))\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', xg_boost)\n",
    "])\n"
   ],
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "nC45fzhtu9Hg",
    "colab_type": "code",
    "outputId": "62ec3e73-9577-4a2a-edd4-eb98de44ab8c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    }
   },
   "source": [
    "train_predict(pipeline)"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.80      0.76    163167\n",
      "         1.0       0.69      0.66      0.68    162314\n",
      "         2.0       0.83      0.78      0.80    161558\n",
      "\n",
      "    accuracy                           0.75    487039\n",
      "   macro avg       0.75      0.75      0.75    487039\n",
      "weighted avg       0.75      0.75      0.75    487039\n",
      "\n",
      "f1 score is 0.7463895964121083, accuracy is 0.7466301466617663\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    },
    "id": "_ImBrPx9u9Hg",
    "colab_type": "text"
   },
   "source": [
    "AdaBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "rBw3bi62u9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ],
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "dXZXdSYFu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "adaBoost = Pipeline([\n",
    "    ('classifier', AdaBoostClassifier()),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', adaBoost)\n",
    "])\n"
   ],
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "tLpkO8nEu9Hg",
    "colab_type": "code",
    "outputId": "30f83c56-bf3a-46fc-da2b-1a37b6f540be",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    }
   },
   "source": [
    "train_predict(pipeline)"
   ],
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.19      0.05      0.08      6581\n",
      "         2.0       0.21      0.09      0.12      6641\n",
      "         3.0       0.20      0.71      0.31      6575\n",
      "         4.0       0.20      0.03      0.06      6573\n",
      "         5.0       0.22      0.13      0.17      6572\n",
      "\n",
      "    accuracy                           0.20     32942\n",
      "   macro avg       0.21      0.20      0.15     32942\n",
      "weighted avg       0.21      0.20      0.15     32942\n",
      "\n",
      "f1 score is 0.1455947998473248, accuracy is 0.2014449638759031\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "fILFPVbOu9Hg",
    "colab_type": "text"
   },
   "source": [
    "\n",
    "Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "CdUJxEzvu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "GEqjRG0mu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "models = [\n",
    "    MultinomialNB(),\n",
    "    BernoulliNB(),\n",
    "    LogisticRegression(),\n",
    "    SGDClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier()\n",
    "]\n",
    "\n",
    "m_names = [m.__class__.__name__ for m in models]\n",
    "\n",
    "models = list(zip(m_names, models))\n",
    "vc = VotingClassifier(estimators=models)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "K7rY3rifu9Hg",
    "colab_type": "text"
   },
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "lXbzlMrzu9Hg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "votingClassifier = Pipeline([\n",
    "    ('classifier', vc),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', votingClassifier)\n",
    "])\n",
    "\n",
    "\n"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    },
    "id": "W-WkjA5eu9Hg",
    "colab_type": "code",
    "outputId": "ac548d25-8794-4a74-f8b2-3fdd3e5359b5",
    "colab": {}
   },
   "source": [
    "train_predict(pipeline)"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/deepLearning/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ],
     "name": "stderr"
    }
   ]
  }
 ]
}