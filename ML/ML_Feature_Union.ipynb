{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad val 'GTKAgg' on line #32\n",
      "\t\"backend      : GTKAgg\n",
      "\"\n",
      "\tin file \"/home/alex/.local/lib/python3.7/site-packages/matplotlib/mpl-data/matplotlibrc\"\n",
      "\tKey backend: Unrecognized backend string 'gtkagg': valid strings are ['GTK3Agg', 'GTK3Cairo', 'MacOSX', 'nbAgg', 'Qt4Agg', 'Qt4Cairo', 'Qt5Agg', 'Qt5Cairo', 'TkAgg', 'TkCairo', 'WebAgg', 'WX', 'WXAgg', 'WXCairo', 'agg', 'cairo', 'pdf', 'pgf', 'ps', 'svg', 'template']\n",
      "/home/alex/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/alex/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/alex/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/alex/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/alex/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/alex/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.pipeline import Pipeline as imPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# For Google colab only\n",
    "\n",
    "df = pd.read_csv(\"../new_clean_sm.csv\")\n",
    "df = df.dropna()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X = df.reviewText.values\n",
    "y = df.overall.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "num = len(df)\n",
    "X, y  = X[:num], y[:num]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# vectoriser = TfidfVectorizer()\n",
    "# X = vectoriser.fit_transform(X)\n",
    "# rus = RandomUnderSampler(sampling_strategy='majority')\n",
    "# X_rus, y_rus = rus.fit_sample(X, y)\n",
    "#\n",
    "#\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# unique, counts  = np.unique(y_rus, return_counts=True)\n",
    "# plt.bar(unique, counts);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X_rus, y_rus, test_size=0.33, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "\n",
    "def train_predict(pipline):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    score = classification_report(y_test, y_pred)\n",
    "    print(score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vectorizers\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "count_vectoriser = Pipeline([\n",
    "                ('countVectoriser', CountVectorizer())\n",
    "            ])\n",
    "\n",
    "tfidf_vectoriser = Pipeline([\n",
    "                ('tfidfVectoriser', TfidfVectorizer(stop_words=STOP_WORDS))\n",
    "            ])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class TextStats(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"Extract features from each document for DictVectorizer\"\"\"\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, posts):\n",
    "        return [{'length': len(text),\n",
    "                 'num_sentences': text.count('.')}\n",
    "                for text in posts]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def make_balance_pipe(steps):\n",
    "    \n",
    "    \n",
    "    x = list(range(len(steps)))\n",
    "    pipeline= [(str(x),y) for x,y in zip(x,steps)]\n",
    "\n",
    "    return imPipeline(pipeline)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "text_features = Pipeline([('length',TextStats()),\n",
    "         ('vect', DictVectorizer())\n",
    "         ])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Naive Bayes\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "naive_bayes = Pipeline([\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', naive_bayes)\n",
    "])\n",
    "\n",
    "pipeline = make_balance_pipe([TfidfVectorizer(),\n",
    "                              RandomUnderSampler(),\n",
    "                              MultinomialNB()])\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features',FeatureUnion([\n",
    "                ('text_stats', text_features),\n",
    "                ('ngram_tfidf',tfidf_vectoriser)\n",
    "            ])),\n",
    "    ('classifier',MultinomialNB())\n",
    "])\n",
    "\n",
    "# pipeline = make_balance_pipe([FeatureUnion([\n",
    "#                 ('text_stats', text_features),\n",
    "#                 ('ngram_tfidf',TfidfVectorizer(stop_words=STOP_WORDS))\n",
    "#\n",
    "#             ]),\n",
    "#                                #RandomUnderSampler(sampling_strategy=\"majority\") ,\n",
    "#                               TomekLinks(n_jobs=4),\n",
    "#                               MultinomialNB()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/deepLearning/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.12      0.15      6697\n",
      "           1       0.21      0.14      0.17      6624\n",
      "           2       0.20      0.28      0.23      6554\n",
      "           3       0.21      0.20      0.21      6542\n",
      "           4       0.23      0.31      0.26      6583\n",
      "\n",
      "    accuracy                           0.21     33000\n",
      "   macro avg       0.21      0.21      0.21     33000\n",
      "weighted avg       0.21      0.21      0.21     33000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_predict(pipeline)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}