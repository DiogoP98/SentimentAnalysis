{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "KoghZU9Zu9EY",
    "outputId": "e0eeeaae-d929-4116-a16c-26898a84ec9c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.pipeline import Pipeline as imPipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics import classification_report, f1_score, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "hKSF3RsZu9EY",
    "outputId": "90816d9e-a67d-4887-8d50-a7a732fcb4e1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# root_path = \"/content/drive/My Drive/notebooks\"\n",
    "# # For Google colab only\n",
    "\n",
    "df = pd.read_csv(f\"../new_clean_sm_100000.csv\")\n",
    "df = df[df['reviewText'].notna()]\n",
    "df = df[~df['reviewText'].str.contains(\".jpg|.png|.jpeg|.tiff|.gif|.bmp|.heif\", regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bsMDuk3Eu9F8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hT55436Ju9F8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### Convert to a two class problem -  optional\n",
    "\n",
    "df = df[df['overall'] != 2]\n",
    "df = df[df['overall'] != 4]\n",
    "df.loc[df['overall'] == 1, 'overall'] = 0\n",
    "df.loc[df['overall'] == 3, 'overall'] = 1\n",
    "df.loc[df['overall'] == 5, 'overall'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ryK1dwGZu9F8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = df.reviewText.values\n",
    "y = df.overall.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LcsFqUOlu9F8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num = len(df)\n",
    "X, y  = X[:num], y[:num]\n",
    "# le = LabelEncoder()\n",
    "# y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZjcShq9u9F8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MhAPlC6Cu9Hg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_predict(pipline):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    score = classification_report(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(score)\n",
    "    print(f\"f1 score is {f1}, accuracy is {accuracy}\")\n",
    "\n",
    "def train_predict_all(pipeline):\n",
    "    out = pipeline.fit(X, y).cv_results_\n",
    "    results_df = pd.DataFrame({'rank': out['rank_test_score'],\n",
    "                          'params': out['params'],\n",
    "                           'cv score (mean)': out['mean_test_score']})\n",
    "    results_df = results_df.sort_values(by=['rank'], ascending=True)\n",
    "    pd.set_option('display.max_colwidth',100)\n",
    "    display(HTML(results_df.to_html()))\n",
    "    return out\n",
    "    # score = classification_report(y_test, y_pred)\n",
    "    # f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    # accuracy = accuracy_score(y_test, y_pred)\n",
    "    # print(score)\n",
    "    # print(f\"f1 score is {f1}, accuracy is {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OrHKgr4Qu9Hg",
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Vectorizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uq3xzk7ru9Hg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "count_vectoriser = Pipeline([\n",
    "                ('countVectoriser', CountVectorizer())\n",
    "            ])\n",
    "\n",
    "tfidf_vectoriser = Pipeline([\n",
    "                ('tfidfVectoriser', TfidfVectorizer(stop_words=STOP_WORDS\n",
    "                                                    ))\n",
    "            ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "brx01xkqaW70"
   },
   "source": [
    "### Stantard Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h0UeIUoqu9Hg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Naive Bayes -  Fine Tune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KLqrDXvZu9Hg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {'vectoriser__tfidfVectoriser__ngram_range': [(1,1),(1,2)],\n",
    "              'classifier__classifier__alpha': [1e-5, 1e-4, 1e-2, 1e-1,1]}\n",
    "\n",
    "\n",
    "# param_grid = {'vectoriser__tfidfVectoriser__ngram_range': [(1,1)],\n",
    "#               'classifier__classifier__alpha': [1e-5]}\n",
    "\n",
    "naive_bayes = Pipeline([\n",
    "    ('classifier', MultinomialNB()),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', naive_bayes)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "NIZko0QUu9Hg",
    "outputId": "f8c07aca-0fae-4ad9-b1aa-9f7ac2c2ef98",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=3)]: Done  50 out of  50 | elapsed: 12.0min finished\n",
      "/home/alex/anaconda3/envs/deepLearning/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ll', 've'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>rank</th>\n      <th>params</th>\n      <th>cv score (mean)</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>{'classifier__classifier__alpha': 1, 'vectoriser__tfidfVectoriser__ngram_range': (1, 2)}</td>\n      <td>0.782966</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>2</td>\n      <td>{'classifier__classifier__alpha': 0.1, 'vectoriser__tfidfVectoriser__ngram_range': (1, 2)}</td>\n      <td>0.778564</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>3</td>\n      <td>{'classifier__classifier__alpha': 0.01, 'vectoriser__tfidfVectoriser__ngram_range': (1, 2)}</td>\n      <td>0.759132</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>4</td>\n      <td>{'classifier__classifier__alpha': 1, 'vectoriser__tfidfVectoriser__ngram_range': (1, 1)}</td>\n      <td>0.752286</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>5</td>\n      <td>{'classifier__classifier__alpha': 0.1, 'vectoriser__tfidfVectoriser__ngram_range': (1, 1)}</td>\n      <td>0.745731</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>{'classifier__classifier__alpha': 0.01, 'vectoriser__tfidfVectoriser__ngram_range': (1, 1)}</td>\n      <td>0.737958</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>{'classifier__classifier__alpha': 0.0001, 'vectoriser__tfidfVectoriser__ngram_range': (1, 1)}</td>\n      <td>0.726656</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>8</td>\n      <td>{'classifier__classifier__alpha': 1e-05, 'vectoriser__tfidfVectoriser__ngram_range': (1, 1)}</td>\n      <td>0.723352</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>{'classifier__classifier__alpha': 0.0001, 'vectoriser__tfidfVectoriser__ngram_range': (1, 2)}</td>\n      <td>0.722207</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10</td>\n      <td>{'classifier__classifier__alpha': 1e-05, 'vectoriser__tfidfVectoriser__ngram_range': (1, 2)}</td>\n      <td>0.710515</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gs_mnb = GridSearchCV(pipeline, param_grid, cv=5, verbose=2, n_jobs=3)\n",
    "final_results = train_predict_all(gs_mnb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LjDB-CiGu9Hg",
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Max Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7pin5oYJu9Hg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YnsfsTlVu9Hg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "max_ent = Pipeline([\n",
    "    ('classifier', LogisticRegression(penalty='l2', C=1.0)),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', max_ent)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3RfVC1Yzu9Hg",
    "outputId": "dc4475f1-a6f8-4745-919f-d8e1ff780e90",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/deepLearning/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.21      0.20      0.20      6581\n",
      "         2.0       0.20      0.20      0.20      6641\n",
      "         3.0       0.20      0.20      0.20      6575\n",
      "         4.0       0.20      0.19      0.19      6573\n",
      "         5.0       0.21      0.23      0.22      6572\n",
      "\n",
      "    accuracy                           0.21     32942\n",
      "   macro avg       0.20      0.21      0.20     32942\n",
      "weighted avg       0.20      0.21      0.20     32942\n",
      "\n",
      "f1 score is 0.20494872650661872, accuracy is 0.2051484427175035\n"
     ]
    }
   ],
   "source": [
    "train_predict(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PfHaBUJUu9Hg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Logistic Regression - Fine Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-8wx5ysOu9Hg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "param_grid={\"classifier__classifier__C\":np.logspace(-3,3,7), \"classifier__classifier__penalty\":[\"l1\",\"l2\"],\n",
    "             'vectoriser__tfidfVectoriser__ngram_range': [(1,1),(1,2)]}\n",
    "\n",
    "logistic_regression = Pipeline([\n",
    "    ('classifier', LogisticRegression()),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', logistic_regression)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "1Zy17E72u9Hg",
    "outputId": "1c11de06-f137-46f6-a56e-31a589e60400",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTerminatedWorkerError\u001B[0m                     Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-40-add5e8e1d856>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mgs_mnb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mRandomizedSearchCV\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpipeline\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparam_grid\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcv\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mresults\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_predict_all\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgs_mnb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-21-08a858b8bd7b>\u001B[0m in \u001B[0;36mtrain_predict_all\u001B[0;34m(pipeline)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mtrain_predict_all\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpipeline\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m     \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcv_results_\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m     results_df = pd.DataFrame({'rank': out['rank_test_score'],\n\u001B[1;32m     13\u001B[0m                           \u001B[0;34m'params'\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'params'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/deepLearning/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    708\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    709\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 710\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    711\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    712\u001B[0m         \u001B[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/deepLearning/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1482\u001B[0m         evaluate_candidates(ParameterSampler(\n\u001B[1;32m   1483\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparam_distributions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mn_iter\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1484\u001B[0;31m             random_state=self.random_state))\n\u001B[0m",
      "\u001B[0;32m~/anaconda3/envs/deepLearning/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[0;34m(candidate_params)\u001B[0m\n\u001B[1;32m    687\u001B[0m                                \u001B[0;32mfor\u001B[0m \u001B[0mparameters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    688\u001B[0m                                in product(candidate_params,\n\u001B[0;32m--> 689\u001B[0;31m                                           cv.split(X, y, groups)))\n\u001B[0m\u001B[1;32m    690\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    691\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/deepLearning/lib/python3.7/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1015\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1016\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretrieval_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1017\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretrieve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1018\u001B[0m             \u001B[0;31m# Make sure that we get a last message telling us we are done\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1019\u001B[0m             \u001B[0melapsed_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_start_time\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/deepLearning/lib/python3.7/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36mretrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    907\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    908\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'supports_timeout'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 909\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    910\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    911\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/deepLearning/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001B[0m in \u001B[0;36mwrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    560\u001B[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001B[1;32m    561\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 562\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfuture\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    563\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mLokyTimeoutError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    564\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/deepLearning/lib/python3.7/concurrent/futures/_base.py\u001B[0m in \u001B[0;36mresult\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    433\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mCancelledError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    434\u001B[0m             \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_state\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0mFINISHED\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 435\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__get_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    436\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    437\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/deepLearning/lib/python3.7/concurrent/futures/_base.py\u001B[0m in \u001B[0;36m__get_result\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    382\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__get_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    383\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_exception\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 384\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_exception\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    385\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    386\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTerminatedWorkerError\u001B[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker. The exit codes of the workers are {SIGKILL(-9)}"
     ]
    }
   ],
   "source": [
    "gs_mnb = RandomizedSearchCV(pipeline, param_grid, cv=5, verbose=2, n_jobs=3)\n",
    "results = train_predict_all(gs_mnb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h1FMt2Evc9ag"
   },
   "source": [
    " Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ObhcwhKifZZU"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdBW7C0HdBfc"
   },
   "outputs": [],
   "source": [
    "decision_tree = Pipeline([\n",
    "    ('classifier', DecisionTreeClassifier()),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', decision_tree)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.20      0.20      0.20      6581\n",
      "         2.0       0.21      0.21      0.21      6641\n",
      "         3.0       0.19      0.19      0.19      6575\n",
      "         4.0       0.20      0.20      0.20      6573\n",
      "         5.0       0.20      0.20      0.20      6572\n",
      "\n",
      "    accuracy                           0.20     32942\n",
      "   macro avg       0.20      0.20      0.20     32942\n",
      "weighted avg       0.20      0.20      0.20     32942\n",
      "\n",
      "f1 score is 0.2010128486000343, accuracy is 0.2010199745006375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_predict(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1yA0yrU-u9Hg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Bagging Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_m6mNSsfu9Hg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_1d7-Lbu9Hg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# random_forest = Pipeline([\n",
    "#     ('classifier', RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = random_grid,\n",
    "#                                       n_iter = 100, cv = 3, verbose=2, random_state=42,\n",
    "#                                       n_jobs = -1)),\n",
    "# ])\n",
    "\n",
    "random_forest = Pipeline([\n",
    "    ('classifier', RandomForestClassifier()),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', random_forest)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C_-o8KD7u9Hg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.20      0.21      0.20      6581\n",
      "         2.0       0.21      0.20      0.20      6641\n",
      "         3.0       0.20      0.20      0.20      6575\n",
      "         4.0       0.20      0.20      0.20      6573\n",
      "         5.0       0.20      0.20      0.20      6572\n",
      "\n",
      "    accuracy                           0.20     32942\n",
      "   macro avg       0.20      0.20      0.20     32942\n",
      "weighted avg       0.20      0.20      0.20     32942\n",
      "\n",
      "f1 score is 0.2028050536791965, accuracy is 0.20281100115354259\n"
     ]
    }
   ],
   "source": [
    "train_predict(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rdPWKCRCu9Hg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Boosting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5F5Imj-Iu9Hg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "loGx-6NOu9Hg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !wget https://s3-us-west-2.amazonaws.com/xgboost-wheels/xgboost-0.81-py2.py3-none-manylinux1_x86_64.whl\n",
    "# !pip uninstall xgboost --yes\n",
    "# !pip install xgboost-0.81-py2.py3-none-manylinux1_x86_64.whl\n",
    "\n",
    "# For Google Colab Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02VNoY6ku9Hg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aG-WP81-u9Hg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    " \"num_class\": 5,\n",
    " \"objective\": \"multi:softmax\",\n",
    "\"n_jobs\":-1}\n",
    "\n",
    "xg_boost = Pipeline([\n",
    "    ('classifier', XGBClassifier(**params))\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', xg_boost)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "nC45fzhtu9Hg",
    "outputId": "62ec3e73-9577-4a2a-edd4-eb98de44ab8c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.72      0.80      0.76    163167\n",
      "         1.0       0.69      0.66      0.68    162314\n",
      "         2.0       0.83      0.78      0.80    161558\n",
      "\n",
      "    accuracy                           0.75    487039\n",
      "   macro avg       0.75      0.75      0.75    487039\n",
      "weighted avg       0.75      0.75      0.75    487039\n",
      "\n",
      "f1 score is 0.7463895964121083, accuracy is 0.7466301466617663\n"
     ]
    }
   ],
   "source": [
    "train_predict(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_ImBrPx9u9Hg",
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "AdaBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rBw3bi62u9Hg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dXZXdSYFu9Hg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "adaBoost = Pipeline([\n",
    "    ('classifier', AdaBoostClassifier()),\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectoriser', tfidf_vectoriser),\n",
    "    ('classifier', adaBoost)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "tLpkO8nEu9Hg",
    "outputId": "30f83c56-bf3a-46fc-da2b-1a37b6f540be",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.19      0.05      0.08      6581\n",
      "         2.0       0.21      0.09      0.12      6641\n",
      "         3.0       0.20      0.71      0.31      6575\n",
      "         4.0       0.20      0.03      0.06      6573\n",
      "         5.0       0.22      0.13      0.17      6572\n",
      "\n",
      "    accuracy                           0.20     32942\n",
      "   macro avg       0.21      0.20      0.15     32942\n",
      "weighted avg       0.21      0.20      0.15     32942\n",
      "\n",
      "f1 score is 0.1455947998473248, accuracy is 0.2014449638759031\n"
     ]
    }
   ],
   "source": [
    "train_predict(pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-WkjA5eu9Hg",
    "outputId": "ac548d25-8794-4a74-f8b2-3fdd3e5359b5",
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/deepLearning/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "train_predict(pipeline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['memory', 'steps', 'verbose', 'vectoriser', 'classifier', 'vectoriser__memory', 'vectoriser__steps', 'vectoriser__verbose', 'vectoriser__tfidfVectoriser', 'vectoriser__tfidfVectoriser__analyzer', 'vectoriser__tfidfVectoriser__binary', 'vectoriser__tfidfVectoriser__decode_error', 'vectoriser__tfidfVectoriser__dtype', 'vectoriser__tfidfVectoriser__encoding', 'vectoriser__tfidfVectoriser__input', 'vectoriser__tfidfVectoriser__lowercase', 'vectoriser__tfidfVectoriser__max_df', 'vectoriser__tfidfVectoriser__max_features', 'vectoriser__tfidfVectoriser__min_df', 'vectoriser__tfidfVectoriser__ngram_range', 'vectoriser__tfidfVectoriser__norm', 'vectoriser__tfidfVectoriser__preprocessor', 'vectoriser__tfidfVectoriser__smooth_idf', 'vectoriser__tfidfVectoriser__stop_words', 'vectoriser__tfidfVectoriser__strip_accents', 'vectoriser__tfidfVectoriser__sublinear_tf', 'vectoriser__tfidfVectoriser__token_pattern', 'vectoriser__tfidfVectoriser__tokenizer', 'vectoriser__tfidfVectoriser__use_idf', 'vectoriser__tfidfVectoriser__vocabulary', 'classifier__memory', 'classifier__steps', 'classifier__verbose', 'classifier__classifier', 'classifier__classifier__C', 'classifier__classifier__class_weight', 'classifier__classifier__dual', 'classifier__classifier__fit_intercept', 'classifier__classifier__intercept_scaling', 'classifier__classifier__l1_ratio', 'classifier__classifier__max_iter', 'classifier__classifier__multi_class', 'classifier__classifier__n_jobs', 'classifier__classifier__penalty', 'classifier__classifier__random_state', 'classifier__classifier__solver', 'classifier__classifier__tol', 'classifier__classifier__verbose', 'classifier__classifier__warm_start'])\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(gs_mnb.estimator.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "ML_TFIDF.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}